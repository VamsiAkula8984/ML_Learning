{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f2cc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdbc18",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7eac351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Affectation of Candour is common enough. One finds it everywhere. But, to be candid without ostenation or design belongs to you and you alone.\n",
    "This was said to Jane by Elizabeth of the Bennett family.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d7a96b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Affectation of Candour is common enough.',\n",
       " 'One finds it everywhere.',\n",
       " 'But, to be candid without ostenation or design belongs to you and you alone.',\n",
       " 'This was said to Jane by Elizabeth of the Bennett family.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = sent_tokenize(sentence)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b6e82a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Affectation',\n",
       " 'of',\n",
       " 'Candour',\n",
       " 'is',\n",
       " 'common',\n",
       " 'enough',\n",
       " '.',\n",
       " 'One',\n",
       " 'finds',\n",
       " 'it',\n",
       " 'everywhere',\n",
       " '.',\n",
       " 'But',\n",
       " ',',\n",
       " 'to',\n",
       " 'be',\n",
       " 'candid',\n",
       " 'without',\n",
       " 'ostenation',\n",
       " 'or',\n",
       " 'design',\n",
       " 'belongs',\n",
       " 'to',\n",
       " 'you',\n",
       " 'and',\n",
       " 'you',\n",
       " 'alone',\n",
       " '.',\n",
       " 'This',\n",
       " 'was',\n",
       " 'said',\n",
       " 'to',\n",
       " 'Jane',\n",
       " 'by',\n",
       " 'Elizabeth',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Bennett',\n",
       " 'family',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = word_tokenize(sentence)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc166b8b",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81cd34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73aef020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affectation-->affect\n",
      "of-->of\n",
      "Candour-->candour\n",
      "is-->is\n",
      "common-->common\n",
      "enough-->enough\n",
      ".-->.\n",
      "One-->one\n",
      "finds-->find\n",
      "it-->it\n",
      "everywhere-->everywher\n",
      ".-->.\n",
      "But-->but\n",
      ",-->,\n",
      "to-->to\n",
      "be-->be\n",
      "candid-->candid\n",
      "without-->without\n",
      "ostenation-->osten\n",
      "or-->or\n",
      "design-->design\n",
      "belongs-->belong\n",
      "to-->to\n",
      "you-->you\n",
      "and-->and\n",
      "you-->you\n",
      "alone-->alon\n",
      ".-->.\n",
      "This-->thi\n",
      "was-->wa\n",
      "said-->said\n",
      "to-->to\n",
      "Jane-->jane\n",
      "by-->by\n",
      "Elizabeth-->elizabeth\n",
      "of-->of\n",
      "the-->the\n",
      "Bennett-->bennett\n",
      "family-->famili\n",
      ".-->.\n"
     ]
    }
   ],
   "source": [
    "#Using PorterStemmer - most widely used.\n",
    "#we can also use regexpStemmer(regex words are removed) \n",
    "# or snowball stemmer(works better than porter)\n",
    "stemmer = PorterStemmer()\n",
    "for word in vocab:\n",
    "    print(word +\"-->\" +stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62459f8a",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a628e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f386b849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affectation-->Affectation\n",
      "of-->of\n",
      "Candour-->Candour\n",
      "is-->is\n",
      "common-->common\n",
      "enough-->enough\n",
      ".-->.\n",
      "One-->One\n",
      "finds-->find\n",
      "it-->it\n",
      "everywhere-->everywhere\n",
      ".-->.\n",
      "But-->But\n",
      ",-->,\n",
      "to-->to\n",
      "be-->be\n",
      "candid-->candid\n",
      "without-->without\n",
      "ostenation-->ostenation\n",
      "or-->or\n",
      "design-->design\n",
      "belongs-->belongs\n",
      "to-->to\n",
      "you-->you\n",
      "and-->and\n",
      "you-->you\n",
      "alone-->alone\n",
      ".-->.\n",
      "This-->This\n",
      "was-->wa\n",
      "said-->said\n",
      "to-->to\n",
      "Jane-->Jane\n",
      "by-->by\n",
      "Elizabeth-->Elizabeth\n",
      "of-->of\n",
      "the-->the\n",
      "Bennett-->Bennett\n",
      "family-->family\n",
      ".-->.\n"
     ]
    }
   ],
   "source": [
    "#Compared to stemming, lemmatization takes time\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for word in vocab:\n",
    "    print(word +\"-->\" +lemmatizer.lemmatize(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07930f",
   "metadata": {},
   "source": [
    "# removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2375c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91910\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cfaf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53302d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['harry',\n",
       " 'potter',\n",
       " 'series',\n",
       " 'seven',\n",
       " 'fantasy',\n",
       " 'novel',\n",
       " 'written',\n",
       " 'british',\n",
       " 'author',\n",
       " 'j.',\n",
       " 'k.',\n",
       " 'rowling',\n",
       " 'novel',\n",
       " 'chronicle',\n",
       " 'life',\n",
       " 'young',\n",
       " 'wizard',\n",
       " ',',\n",
       " 'harry',\n",
       " 'potter',\n",
       " ',',\n",
       " 'his',\n",
       " 'friend',\n",
       " ',',\n",
       " 'ron',\n",
       " 'weasley',\n",
       " 'hermione',\n",
       " 'granger',\n",
       " ',',\n",
       " 'are',\n",
       " 'student',\n",
       " 'hogwarts',\n",
       " 'school',\n",
       " 'witchcraft',\n",
       " 'wizardry',\n",
       " 'the',\n",
       " 'main',\n",
       " 'story',\n",
       " 'arc',\n",
       " 'concern',\n",
       " 'harry',\n",
       " \"'s\",\n",
       " 'conflict',\n",
       " 'lord',\n",
       " 'voldemort',\n",
       " ',',\n",
       " 'a',\n",
       " 'dark',\n",
       " 'wizard',\n",
       " 'intends',\n",
       " 'become',\n",
       " 'immortal',\n",
       " ',',\n",
       " 'overthrow',\n",
       " 'the',\n",
       " 'wizard',\n",
       " 'governing',\n",
       " 'body',\n",
       " 'known',\n",
       " 'a',\n",
       " 'the',\n",
       " 'ministry',\n",
       " 'of',\n",
       " 'magic',\n",
       " ',',\n",
       " 'subjugate',\n",
       " 'wizard',\n",
       " 'muggles',\n",
       " '(',\n",
       " 'non-magical',\n",
       " 'people',\n",
       " ')']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \"\"\"Harry Potter is a series of seven fantasy novels written by British author J. K. Rowling.\n",
    " The novels chronicle the lives of a young wizard, Harry Potter, and his friends, Ron Weasley and Hermione Granger, all of whom are students at Hogwarts School of Witchcraft \n",
    " and Wizardry. The main story arc concerns Harry's conflict with Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as \n",
    " the Ministry of Magic, and subjugate all wizards and Muggles (non-magical people).\"\"\"\n",
    "\n",
    "words = word_tokenize(document.lower())\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(len(lemmatized_words))\n",
    "\n",
    "for lemma in lemmatized_words:\n",
    "    if lemma in stop_words or lemma == '.':\n",
    "        lemmatized_words.remove(lemma)\n",
    "print(len(lemmatized_words))\n",
    "    \n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390aaa9b",
   "metadata": {},
   "source": [
    "# Text to Vector techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e76141",
   "metadata": {},
   "source": [
    "bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fe6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
